import{_ as i}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as t,d as s,o as d}from"./app-I68t-fKX.js";const c={};function o(n,e){return d(),t("div",null,e[0]||(e[0]=[s(`<p>我们通常说，<code>Redis</code> 是单线程，主要是指 <code>Redis</code> 的网络 IO 和键值对读写是由一个线程来完成的，这也是 <code>Redis</code> 对外提供键值存储服务的主要流程。但是 <code>Redis</code> 的其他功能，比如说持久化、异步删除、集群数据同步等，其实是由额外的线程执行的</p><p>所以严格来说，<code>Redis</code> 并不是单线程，但是我们一般把 <code>Redis</code> 称为单线程高性能<br> 这也促使我们提问：<strong>为什么用单线程？为什么单线程能这么快？</strong></p><p>要弄明白这个问题，我们需要深入学习 <code>Redis</code> 的单线程设计机制以及多路复用机制。在我们以后调优 <code>Redis</code> 时，也能更有针对性地避免会导致 <code>Redis</code> 单线程阻塞的操作，例如执行复杂度高的命令</p><h2 id="redis-为什么使用单线程" tabindex="-1"><a class="header-anchor" href="#redis-为什么使用单线程"><span>Redis 为什么使用单线程？</span></a></h2><h3 id="多线程的开销" tabindex="-1"><a class="header-anchor" href="#多线程的开销"><span>多线程的开销</span></a></h3><p>我们经常会听到一种说法，&quot;使用多线程，可以增加系统吞吐率，或是可以增加系统扩展性&quot;<br> 的确，对于一个多线程的系统来说，在有合理的资源分配的情况下，可以增加系统中处理请求操作的资源实体，进而提升系统能够同时处理的请求数，即吞吐率</p><p>但是，通常情况下，在我们采用多线程后，如果没有良好的系统设计，实际得到的结果，其实并没有那么良好。在一开始增加线程数时，系统吞吐率会增加，但是再进一步增加线程时，系统吞吐率就增长迟缓了，有时还会出现下降的情况</p><figure><img src="https://cdn.jsdelivr.net/gh/logycoconut/pic-repo/tech/20240228165120.png" alt="image.png" tabindex="0" loading="lazy"><figcaption>image.png</figcaption></figure><h3 id="线程数与系统吞吐率" tabindex="-1"><a class="header-anchor" href="#线程数与系统吞吐率"><span>线程数与系统吞吐率</span></a></h3><p>为什么会出现这种情况呢？一个关键的瓶颈在于，系统中通常会存在被多线程同时访问的共享资源，比如一个共享的数据结构。当有多个线程要修改这个共享资源时，为了保证共享资源的正确性，就需要有额外的机制进行保证，而这个额外的机制，就会带来额外的开销</p><p>举个例子，<code>Redis</code> 有 List 的数据类型，并提供 LPOP 和 LPUSH 操作<br> 假设 <code>Redis</code> 采用多线程设计，如下图所示，为了保证队列长度的正确性，<code>Redis</code> 需要让线程 A 和 B 的 LPOP、LPUSH 操作串行执行，否则，就可能得到错误的长度结果<br> 这就是<strong>多线程编程模式面临的共享资源的并发访问控制问题</strong><br><img src="https://cdn.jsdelivr.net/gh/logycoconut/pic-repo/tech/20240228165701.png" alt="image.png" loading="lazy"></p><h3 id="多线程并发访问-redis" tabindex="-1"><a class="header-anchor" href="#多线程并发访问-redis"><span>多线程并发访问 Redis</span></a></h3><p>并发访问控制一直是多线程开发中的一个难点问题，如果没有精细的设计，比如说，只是简单地采用一个粗粒度互斥锁，就会出现不理想的结果：即使增加了线程，大部分线程也在等待获取访问共享资源的互斥锁，并行变串行，系统吞吐率并没有随着线程的增加而增加</p><p>而且采用多线程开发一般会引入同步原语来保护共享资源的并发访问，这也会降低系统代码的易调试性和可维护性<br> 为了避免这些问题，<code>Redis</code> 直接采用了单线程模式</p><h2 id="单线程-redis-为什么这么快" tabindex="-1"><a class="header-anchor" href="#单线程-redis-为什么这么快"><span>单线程 Redis 为什么这么快</span></a></h2><p>通常来说，单线程的处理能力要比多线程差很多，但是 <code>Redis</code> 却能使用单线程模型达到每秒数十万级别的处理能力，这是为什么呢</p><ul><li>一方面，Redis 的操作大部分在内存中完成，再加上它采用了高效的数据结构，例如哈希表和跳表，这是它实现高性能的一个重要原因</li><li>另一方面，Redis 采用了多路复用机制，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率</li></ul><p>我们需要弄明白网络操作的基本 IO 模型和潜在的阻塞点<br> 毕竟，Redis 采用单线程进行 IO，如果线程被阻塞了，就无法进行多路复用了</p><h3 id="基本-io-模型与阻塞点" tabindex="-1"><a class="header-anchor" href="#基本-io-模型与阻塞点"><span>基本 IO 模型与阻塞点</span></a></h3><p>以 GET 请求为例，键值数据库为了处理一个 GET 请求，需要监听客户端请求（bind/listen），和客户端建立连接（accept），从 socket 中读取请求（recv），解析客户端发送请求（parse），根据请求类型读取键值数据（get），最后给客户端返回结果，即向 socket 中写回数据（send）</p><figure><img src="https://cdn.jsdelivr.net/gh/logycoconut/pic-repo/tech/20240228170528.png" alt="Redis基本IO模型" tabindex="0" loading="lazy"><figcaption>Redis基本IO模型</figcaption></figure><p>既然 Redis 是单线程，那么最基本的一种实现是在一个线程中一次执行上面说的这些操作</p><p>但是，在这里的网络 IO 操作中，有潜在的阻塞点，分别是 accept 和 recv<br> 当 Redis 监听到一个客户端有连接请求，但一直未能建立起连接时，会阻塞在 accept 函数这里，导致其他客户端无法和 Redis 建立连接；类似的，当 Redis 通过 recv 从一个客户端读取数据时，如果数据一直没有到达，Redis 也会一直阻塞在 recv</p><p>这就导致 Redis 整个线程阻塞，无法处理其他客户端请求，效率很低<br> 不过幸运的是，socket 网络模式本身支持非阻塞模式</p><h3 id="非阻塞模式" tabindex="-1"><a class="header-anchor" href="#非阻塞模式"><span>非阻塞模式</span></a></h3><p>Socket 网络模型的非阻塞模式设置，主要体现在三个关键的函数调用</p><p>在 Socket 模型中，不同操作调用后会返回不同的套接字类型<br> socket () 方法会返回主动套接字，然后调用 listen() 方法，将主动套接字转化为监听套接字，此时，可以监听来自客户端的连接请求。最后，调用 accept () 方法接收到达的客户端连接，并返回已连接套接字</p><figure><img src="https://cdn.jsdelivr.net/gh/logycoconut/pic-repo/tech/20240228180242.png" alt="Redis套接字类型与非阻塞设置" tabindex="0" loading="lazy"><figcaption>Redis套接字类型与非阻塞设置</figcaption></figure><p>针对监听套接字，我们可以设置非阻塞模式<br> 当 Redis 调用 accept 但一直未有连接请求到达时，Redis 线程可以返回处理其他操作，而不用一直等待<br><em>但是需要注意的是，调用 accept 时，已经存在监听套接字了</em></p><p>虽然 Redis 线程可以不用继续等待，但是总得有机制继续在监听套接字上等待后续连接请求，并在有请求时通知 Redis</p><p>类似的，我们也可以针对已连接套接字设置非阻塞模式<br> Redis 调用 recv 后，如果已连接套接字上一直没有数据到达，Redis 线程同样可以返回处理其他操作（<em>同样的，我们也需要一个机制继续监听该已连接套接字，并在有数据达到时通知 Redis</em>）</p><p>这样才能保证 Redis 线程，既不会像基本 IO 模型中一直在阻塞点等待，也不会导致 Redis 无法处理实际到达的连接请求或数据</p><h3 id="基于多路复用的高性能-io-模型" tabindex="-1"><a class="header-anchor" href="#基于多路复用的高性能-io-模型"><span>基于多路复用的高性能 IO 模型</span></a></h3><p>Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流，就是常说的 select/epoll 机制<br> 简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字<br> 内核会一直监听这些套接字上的连接请求或数据请求，一旦有请求到达，就会交给 Redis 处理，这就实现了一个 Redis 线程处理多个 IO 流的效果</p><p><img src="https://cdn.jsdelivr.net/gh/logycoconut/pic-repo/tech/20240228181106.png" alt="基于多路复用的Redis高性能IO模型" loading="lazy"><br> 图中的多个 FD 就是刚才所说的多个套接字</p><p>Redis 网络框架调用 epoll 机制，让内核监听这些套接字<br> 此时，Redis 线程不会阻塞在某一个特定的客户端请求处理上，因此可以同时和多个客户端连接并处理请求，从而提高并发性</p><p>为了在请求到达时能够通知到 Redis 线程，select/epoll 提供了基于事件的回调机制，即处理不同时间的发生，调用相应的处理函数</p><p>当 select/epoll 一旦检测到 FD 上有请求到达时，就会触发相应事件<br> 这些事件会被放进一个事件列表，Redis 单线程对该事件队列不断进行处理<br> 这样一来，Redis 无需一直轮训是否有请求实际发生，避免 CPU 资源浪费</p><p>同时，Redis 在对事件队列中的事件进行处理时，会调用相应的处理函数，这就实现了基于事件的回调。因为 Redis 一直在对事件队列进行处理，所以能及时响应客户端请求，提升 Redis 的性能</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>以连接请求和读数据请求为例，具体解释一下</span></span>
<span class="line"><span>这两个请求分别对应 Accept 事件和 Read 事件，Redis 分别对这两个事件注册 accept 和 get 回调函数。当 Linux 内核监听到有连接请求或读数据请求时，就会触发 Accept 事件和 Read 事件，此时，内核就会回调 Redis 相应的 accept 和 get 函数进行处理。</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div>`,40)]))}const r=i(c,[["render",o],["__file","03_高性能 IO 模型：为什么单线程 Redis 能那么快？.html.vue"]]),l=JSON.parse(`{"path":"/project/Redis/Redis%20%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%20-%20%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/03_%E9%AB%98%E6%80%A7%E8%83%BD%20IO%20%E6%A8%A1%E5%9E%8B%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8D%95%E7%BA%BF%E7%A8%8B%20Redis%20%E8%83%BD%E9%82%A3%E4%B9%88%E5%BF%AB%EF%BC%9F.html","title":"03_高性能 IO 模型：为什么单线程 Redis 能那么快？","lang":"zh-CN","frontmatter":{"title":"03_高性能 IO 模型：为什么单线程 Redis 能那么快？","tag":["Redis"],"category":["Redis 核心技术与实战"],"description":"我们通常说，Redis 是单线程，主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程。但是 Redis 的其他功能，比如说持久化、异步删除、集群数据同步等，其实是由额外的线程执行的 所以严格来说，Redis 并不是单线程，但是我们一般把 Redis 称为单线程高性能 这也促使我们提问...","head":[["meta",{"property":"og:url","content":"https://logycoconut.github.io/project/Redis/Redis%20%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%20-%20%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/03_%E9%AB%98%E6%80%A7%E8%83%BD%20IO%20%E6%A8%A1%E5%9E%8B%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8D%95%E7%BA%BF%E7%A8%8B%20Redis%20%E8%83%BD%E9%82%A3%E4%B9%88%E5%BF%AB%EF%BC%9F.html"}],["meta",{"property":"og:site_name","content":"logycoconut's k-lab"}],["meta",{"property":"og:title","content":"03_高性能 IO 模型：为什么单线程 Redis 能那么快？"}],["meta",{"property":"og:description","content":"我们通常说，Redis 是单线程，主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程。但是 Redis 的其他功能，比如说持久化、异步删除、集群数据同步等，其实是由额外的线程执行的 所以严格来说，Redis 并不是单线程，但是我们一般把 Redis 称为单线程高性能 这也促使我们提问..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://cdn.jsdelivr.net/gh/logycoconut/pic-repo/tech/20240228165120.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-02-11T14:19:39.000Z"}],["meta",{"property":"article:tag","content":"Redis"}],["meta",{"property":"article:modified_time","content":"2025-02-11T14:19:39.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"03_高性能 IO 模型：为什么单线程 Redis 能那么快？\\",\\"image\\":[\\"https://cdn.jsdelivr.net/gh/logycoconut/pic-repo/tech/20240228165120.png\\",\\"https://cdn.jsdelivr.net/gh/logycoconut/pic-repo/tech/20240228165701.png\\",\\"https://cdn.jsdelivr.net/gh/logycoconut/pic-repo/tech/20240228170528.png\\",\\"https://cdn.jsdelivr.net/gh/logycoconut/pic-repo/tech/20240228180242.png\\",\\"https://cdn.jsdelivr.net/gh/logycoconut/pic-repo/tech/20240228181106.png\\"],\\"dateModified\\":\\"2025-02-11T14:19:39.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"logycoconut\\",\\"url\\":\\"https://logycoconut.github.io/\\"}]}"]]},"headers":[{"level":2,"title":"Redis 为什么使用单线程？","slug":"redis-为什么使用单线程","link":"#redis-为什么使用单线程","children":[{"level":3,"title":"多线程的开销","slug":"多线程的开销","link":"#多线程的开销","children":[]},{"level":3,"title":"线程数与系统吞吐率","slug":"线程数与系统吞吐率","link":"#线程数与系统吞吐率","children":[]},{"level":3,"title":"多线程并发访问 Redis","slug":"多线程并发访问-redis","link":"#多线程并发访问-redis","children":[]}]},{"level":2,"title":"单线程 Redis 为什么这么快","slug":"单线程-redis-为什么这么快","link":"#单线程-redis-为什么这么快","children":[{"level":3,"title":"基本 IO 模型与阻塞点","slug":"基本-io-模型与阻塞点","link":"#基本-io-模型与阻塞点","children":[]},{"level":3,"title":"非阻塞模式","slug":"非阻塞模式","link":"#非阻塞模式","children":[]},{"level":3,"title":"基于多路复用的高性能 IO 模型","slug":"基于多路复用的高性能-io-模型","link":"#基于多路复用的高性能-io-模型","children":[]}]}],"git":{"createdTime":1709184530000,"updatedTime":1739283579000,"contributors":[{"name":"logycoconut","username":"logycoconut","email":"logycoconut@foxmail.com","commits":2,"url":"https://github.com/logycoconut"}]},"readingTime":{"minutes":7.84,"words":2351},"filePathRelative":"project/Redis/Redis 核心技术与实战 - 极客时间/03_高性能 IO 模型：为什么单线程 Redis 能那么快？.md","localizedDate":"2024年2月29日","autoDesc":true}`);export{r as comp,l as data};
