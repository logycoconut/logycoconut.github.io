import{_ as o}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as t,d as p,o as c}from"./app-I68t-fKX.js";const i={};function r(l,e){return c(),t("div",null,e[0]||(e[0]=[p('<p>如果 Redis 发生了宕机，AOF 和 RDB 可以分别通过回放日志和重新读入 RDB 文件的方式恢复数据，从而保证尽量少丢失数据，提升可靠性</p><p>不过，即使用了这两种方法，也依然存在服务不可用的问题<br> 比如说，我们在实际使用时只运行了一个 Redis 实例，那么，如果这个实例宕机了，它在恢复期间，是无法服务新来的数据存取请求的</p><p>那我们总说的 Redis 具有高可靠性，又是什么意思呢？<br> 其实，这有两层含义</p><ul><li>数据尽量少丢失</li><li>服务尽量少中断</li></ul><p>AOF 和 RDB 保证了前者，而对于后者，Redis 的做法就是<strong>增加副本冗余量</strong>，将一份数据同时保存在多个实例上。即使有一个实例出现了故障，需要经过一段时间才能恢复，其他实例也可以对外提供服务，不会影响业务使用</p><p>多实例保存同一份数据，听起来好像很不错，但是，我们必须要考虑一个问题：这么多副本，它们之间的数据如何保持一致呢？数据读写操作可以发给所有的实例吗？</p><p>实际上，Redis 提供了主从库模式，以保证数据副本的一致，主从库之间采用的是读写分离的方式</p><ul><li>读操作：主库、从库都可以接收</li><li>写操作：首先到主库执行，然后主库将写操作同步给从库</li></ul><figure><img src="https://cdn.jsdelivr.net/gh/logycoconut/pic-repo/tech/20240229162111.png" alt="Redis主从库和读写分离" tabindex="0" loading="lazy"><figcaption>Redis主从库和读写分离</figcaption></figure><p>那么，为什么要采用读写分离的方式呢？</p><p>设想一下，如果在上图中，不管是主库还是从库，都能接收客户端的写操作，那么，一个直接的问题就是：如果客户端对同一个数据前后修改了三次，每一次的修改都发送到不同的实例上，在不同的实例上执行，那么这个数据在这三个实例上的副本就不一致了，在读取这个数据的时候，就可能读取到旧值</p><p>如果我们非要保持这个数据在三个实例上一致，就要涉及到加锁、实例间协商是否完成修改等一系列操作，但这会带来巨额的花销，当然是不能接受的</p><p>而主从库模式一旦采用了读写分离，所有数据的修改只会在主库上进行，不用协调三个实例<br> 主库有了最新的数据后，会同步给从库，这样，主从库的数据就是一致的</p><p>那么，主从库同步是如何完成的呢？主库数据是一次性传给从库，还是分批同步？要是主从库间的网络断连了，数据还能保持一致吗？</p><h3 id="主从库间如何进行第一次同步" tabindex="-1"><a class="header-anchor" href="#主从库间如何进行第一次同步"><span>主从库间如何进行第一次同步？</span></a></h3><blockquote><p>Redis 实例建立主从库模式后的规定动作</p></blockquote><p>当我们启动多个 Redis 实例时，它们相互之间就可以通过 replicaof 命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步<br><em>Redis 5.0 之前使用 slaveof</em></p><p>例如，现在有实例 1 (ip：172.16.19.3) 和实例 2（ip：172.16.19.5），我们在实例 2 上执行以下命令后，实例 2 就变成了实例 1 的从库，并从实例 1 上复制数据<br><code>replicaof 172.16.19.3 6379</code></p><figure><img src="https://cdn.jsdelivr.net/gh/logycoconut/pic-repo/tech/20240229162926.png" alt="主从库第一次同步的流程" tabindex="0" loading="lazy"><figcaption>主从库第一次同步的流程</figcaption></figure><p>第一次同步分为三个阶段，从上图可以大致说明</p><ul><li>第一阶段是主从库间建立连接、协商同步的过程，主要是为全量复制做准备<br> 在这一步，从库和主库建立起链接，并告诉主库即将进行同步是，主库确认回复后，主从库间就可以开始同步了</li></ul><p>具体来说，从库给主库发送 psync 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制（psync 命令包含了主库的 runID 和复制进度 offset 两个参数）<br><em>runID 是每个 Redis 实例启动时都会自动生成的一个随机 ID，用来唯一标记这个实例。当从库和主库第一次复制时，因为不知道主库的 runID，所以将 runID 设为？</em><br><em>offset 此刻设为-1，表示第一次复制</em></p><p>主库收到 psync 命令后，会用 FULLRESYNC 响应命令带上两个参数：主库 runID 和主库目前的复制进度 offset，返回给从库。从库收到响应后，会记录下这两个参数<br><em>FULLRESYNC 响应表示第一次复制采用的全量复制</em></p><ul><li>第二阶段，主库将所有数据同步给从库，从库收到数据后，在本地完成数据加载，这个过程依赖于内存快照生成的 RDB 文件<br> 具体来说，主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。从库收到 RDB 文件后，后先清空当前数据库，然后加载 EDB 文件<br><em>这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据，为了避免之前数据的影响，从库需要先把当前数据库清空</em></li></ul><p>在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接受请求，否则，Redis 的服务就被中断了<br> 但是这些请求中的写操作并没有记录到刚刚生成的 RDB 文件中<br> 为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录 RDB 文件生成后收到的所有写操作</p><ul><li>第三阶段，主库会把第二阶段执行过程中心收到的写命令，再发送给从库<br> 当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再执行这些操作<br> 这样一来，主从库就实现同步了</li></ul><h3 id="主从级联模式分担全量复制时的主库压力" tabindex="-1"><a class="header-anchor" href="#主从级联模式分担全量复制时的主库压力"><span>主从级联模式分担全量复制时的主库压力</span></a></h3><p>通过分析主从库间第一次数据同步的过程，可以看到，一次全量复制中，对于主库来说，需要完成两个耗时的操作：生成 RDB 文件和传输 RDB 文件</p><p>如果从库数量很多，而且都要和主库进行全量复制的话，就会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步<br> fork 这个操作会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢<br> 此外，传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力</p><p>有没有好的解决方法可以分担主库压力呢？<br> 其实这就是&quot;主-从-从&quot;模式</p><p>在刚才的介绍中，所有的从库都是和主库连接，所有的全量复制也都是和主库进行的<br> 现在我们可以通过&quot;主-从-从&quot;模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库中</p><p>简单来说，我们在部署主从集群的时候，可以手动选择一个从库（比如内存资源配置较高的从库），用来级联其他的从库<br> 然后我们可以再选择一些从库，在这些从库上执行如下命令，让它们和刚才所选的从库，建立起主从关系<br><code>replicaof 所选从库IP 6379</code></p><p>这样一来，这些从库就会知道，在进行同步时，不用再和主库进行交互了，只要和级联的从库进行写操作同步就行了，这就可以减轻主库上的压力</p><figure><img src="https://cdn.jsdelivr.net/gh/logycoconut/pic-repo/tech/20240229165302.png" alt="级联的“主-从-从”模式" tabindex="0" loading="lazy"><figcaption>级联的“主-从-从”模式</figcaption></figure><p>一旦主从库完成了全量复制，它们之间就会一直维护一个网络连接，主库会通过这个连接将后续陆续收到的命令操作再同步给从库，这个过程也称为基于长连接的命令传播，可以避免频繁建立连接的开销</p><p>听上去似乎很简单，但不可忽视的是，这个过程中存在风险点，最常见的就是网络断连或阻塞<br> 如果网络断连，主从库之间就无法进行命令传播了，从库的数据自然也就没办法和主库保持一致了，客户端就可能从从库读到旧数据</p><h3 id="主从库间网络断了怎么办" tabindex="-1"><a class="header-anchor" href="#主从库间网络断了怎么办"><span>主从库间网络断了怎么办？</span></a></h3><p>在 Redis 2.8 之前，如果主从库在命令传播时出现了网络闪断，那么，从库就会和主库重新进行一次全量复制，开销非常大</p><p>从 Redis 2.8 开始，网络断了之后，主从库会采用增量复制的方式继续同步<br> 听名字大概就猜到它和全量复制的不同：全量复制是同步所有数据，而增量复制只会把主从库网络断连期间主库收到的命令，同步给从库</p><p>那么，增量复制时，主从库之间具体是怎么保持同步的呢？这里的奥妙就在于 <code>repl_backlog_buffer</code> 这个缓冲区</p><p>当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也会把这些操作命令也写入 <code>repl_backlog_buffer</code> 这个缓冲区</p><p><code>repl_backlog_buffer</code> 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己读到的位置</p><p>刚开始的时候，主库和从库的写读位置在一起，这算是它们的起始位置<br> 随着主库不断接收新的写操作，它在缓冲区中的写位置会逐步偏离起始位置，我们通常用偏移量来衡量这个偏移距离的大小，对主库来说，对应的偏移量就是 <code>master_repl_offset</code><br> 主库接收的新写操作越多，这个值就越大</p><p>同样，从库在复制完写操作命令后，它在缓冲区中的读位置也开始逐步偏移刚才的起始位置<br> 此时，从库已复制的偏移量 <code>slave_repl_offset</code> 也在不断增加<br> 正常情况下，这两个偏移量基本相等</p><figure><img src="https://cdn.jsdelivr.net/gh/logycoconut/pic-repo/tech/20240229174508.png" alt="Redis repl_backlog_buffer的使用" tabindex="0" loading="lazy"><figcaption>Redis repl_backlog_buffer的使用</figcaption></figure><p>主从库的连接恢复之后，从库首先会给主库发送 <code>psync</code> 命令，并把自己当前的 <code>slave_repl_offset</code> 发给主库，主库会判断自己的 <code>master_repl_offset</code> 和 <code>slave_repl_offset</code> 之间的差距</p><p>在网络断连阶段，主库可能会收到新的写操作，所以一般来说 <code>master_repl_offset</code> 会大于 <code>slave_repl_offset</code><br> 此时，主库只用把 <code>master_repl_offset</code> 和 <code>slave_repl_offset</code> 之间的命令操作同步给从库就行</p><p>我们回顾一下增量复制的流程</p><figure><img src="https://cdn.jsdelivr.net/gh/logycoconut/pic-repo/tech/20240229175328.png" alt="Redis增量复制流程" tabindex="0" loading="lazy"><figcaption>Redis增量复制流程</figcaption></figure><p>不过，需要注意的是，因为 <code>repl_backlog_buffer</code> 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作<br> 如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致</p><p>因此，我们要想办法避免这一情况<br> 一般而言，我们可以调整 <code>repl_backlog_size</code> 这个参数，这个参数和所需的缓冲空间大小有关<br> 缓冲空间的计算公式是：<code>缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小</code></p><p>在实际应用中，考虑到可能存在一些突发的请求压力，我们通常需要把这个缓冲空间扩大一倍<br> 即 <code>repl_backlog_size = 缓冲空间 * 2</code></p><p>举个例子，如果主库每秒写入 2000 个操作，每个操作的大小为 2KB，网络每秒能传输 1000 个操作，那么，有 1000 个操作需要缓冲起来，这就需要至少 2MB 的缓冲空间，否则，新写的命令就会覆盖掉就操作了<br> 为了应对可能的突发压力，最终 <code>repl_backlog_size</code> 设置为 4MB</p><p>这样一来，增量复制时主从库的数据不一致风险就降低了<br> 不过，如果并发请求量非常大，连两倍的缓冲空间都存不下新操作请求的话，此时，主从库数据仍然可能不一致。</p><p>针对这种情况，一方面，你可以根据 Redis 所在服务器的内存资源再适当增加 <code>repl_backlog_size</code> 值，比如说设置成缓冲空间大小的 4 倍<br> 另一方面，你可以考虑使用切片集群来分担单个主库的请求压力（这就是后续内容啦）</p>',55)]))}const s=o(i,[["render",r],["__file","06_数据同步：主从库如何实现数据一致.html.vue"]]),a=JSON.parse(`{"path":"/project/Redis/Redis%20%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%20-%20%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/06_%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%EF%BC%9A%E4%B8%BB%E4%BB%8E%E5%BA%93%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4.html","title":"06_数据同步：主从库如何实现数据一致","lang":"zh-CN","frontmatter":{"title":"06_数据同步：主从库如何实现数据一致","tag":["Redis"],"category":["Redis 核心技术与实战"],"description":"如果 Redis 发生了宕机，AOF 和 RDB 可以分别通过回放日志和重新读入 RDB 文件的方式恢复数据，从而保证尽量少丢失数据，提升可靠性 不过，即使用了这两种方法，也依然存在服务不可用的问题 比如说，我们在实际使用时只运行了一个 Redis 实例，那么，如果这个实例宕机了，它在恢复期间，是无法服务新来的数据存取请求的 那我们总说的 Redis ...","head":[["meta",{"property":"og:url","content":"https://logycoconut.github.io/project/Redis/Redis%20%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%20-%20%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/06_%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%EF%BC%9A%E4%B8%BB%E4%BB%8E%E5%BA%93%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4.html"}],["meta",{"property":"og:site_name","content":"logycoconut's k-lab"}],["meta",{"property":"og:title","content":"06_数据同步：主从库如何实现数据一致"}],["meta",{"property":"og:description","content":"如果 Redis 发生了宕机，AOF 和 RDB 可以分别通过回放日志和重新读入 RDB 文件的方式恢复数据，从而保证尽量少丢失数据，提升可靠性 不过，即使用了这两种方法，也依然存在服务不可用的问题 比如说，我们在实际使用时只运行了一个 Redis 实例，那么，如果这个实例宕机了，它在恢复期间，是无法服务新来的数据存取请求的 那我们总说的 Redis ..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://cdn.jsdelivr.net/gh/logycoconut/pic-repo/tech/20240229162111.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-02-11T14:19:39.000Z"}],["meta",{"property":"article:tag","content":"Redis"}],["meta",{"property":"article:modified_time","content":"2025-02-11T14:19:39.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"06_数据同步：主从库如何实现数据一致\\",\\"image\\":[\\"https://cdn.jsdelivr.net/gh/logycoconut/pic-repo/tech/20240229162111.png\\",\\"https://cdn.jsdelivr.net/gh/logycoconut/pic-repo/tech/20240229162926.png\\",\\"https://cdn.jsdelivr.net/gh/logycoconut/pic-repo/tech/20240229165302.png\\",\\"https://cdn.jsdelivr.net/gh/logycoconut/pic-repo/tech/20240229174508.png\\",\\"https://cdn.jsdelivr.net/gh/logycoconut/pic-repo/tech/20240229175328.png\\"],\\"dateModified\\":\\"2025-02-11T14:19:39.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"logycoconut\\",\\"url\\":\\"https://logycoconut.github.io/\\"}]}"]]},"headers":[{"level":3,"title":"主从库间如何进行第一次同步？","slug":"主从库间如何进行第一次同步","link":"#主从库间如何进行第一次同步","children":[]},{"level":3,"title":"主从级联模式分担全量复制时的主库压力","slug":"主从级联模式分担全量复制时的主库压力","link":"#主从级联模式分担全量复制时的主库压力","children":[]},{"level":3,"title":"主从库间网络断了怎么办？","slug":"主从库间网络断了怎么办","link":"#主从库间网络断了怎么办","children":[]}],"git":{"createdTime":1709184530000,"updatedTime":1739283579000,"contributors":[{"name":"logycoconut","username":"logycoconut","email":"logycoconut@foxmail.com","commits":3,"url":"https://github.com/logycoconut"}]},"readingTime":{"minutes":10.86,"words":3259},"filePathRelative":"project/Redis/Redis 核心技术与实战 - 极客时间/06_数据同步：主从库如何实现数据一致.md","localizedDate":"2024年2月29日","autoDesc":true}`);export{s as comp,a as data};
